# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added

- Initial release preparation
- Comprehensive build pipeline with bundle analysis
- Package validation and optimization tools

## [1.0.0] - 2024-12-19

### Added

- **Core Features**

  - Unified interface for multiple LLM providers (OpenAI, Claude, Groq, Grok)
  - Provider abstraction layer with consistent API
  - Comprehensive TypeScript support with full type definitions
  - Streaming chat completions for all providers
  - Tool/function calling support across providers
  - Cost tracking and estimation for all models
  - Error handling and classification system
  - Health checking and provider monitoring

- **Provider Support**

  - **OpenAI Provider**: Full GPT-4, GPT-3.5-turbo, GPT-4o support with all variants
  - **Claude Provider**: Claude 3.5 Sonnet, Opus, Haiku with vision support
  - **Groq Provider**: Llama 3.1, Mixtral, Gemma models with ultra-fast inference
  - **Grok Provider**: grok-beta and grok-vision-beta models

- **Advanced Features**

  - Real-time streaming responses with abort control
  - Automatic token counting and cost calculation
  - Response standardization and metadata enhancement
  - Model capability detection and validation
  - Rate limiting and retry logic
  - Comprehensive error recovery strategies

- **Developer Experience**

  - Easy provider switching without code changes
  - Consistent request/response formats
  - Built-in TypeScript intellisense
  - Comprehensive documentation and examples
  - Jest testing framework with 80%+ coverage
  - ESLint configuration for code quality

- **Build & Distribution**
  - Dual package support (CommonJS + ESM)
  - Tree-shakeable bundles for optimal size
  - TypeScript declaration files
  - Bundle size optimization (< 50KB)
  - Automated build validation
  - CI/CD ready configuration

### Technical Implementation

- **Architecture**: Three-layer system (Provider â†’ Abstraction â†’ User Interface)
- **Type Safety**: Comprehensive TypeScript definitions for all APIs
- **Modularity**: Provider adapters can be used independently
- **Performance**: Optimized HTTP clients with connection pooling
- **Reliability**: Robust error handling with automatic retries
- **Monitoring**: Built-in analytics and usage tracking

### Dependencies

- **Runtime**: `axios` for HTTP requests
- **Peer Dependencies**: Provider SDKs (`openai`, `anthropic`, `@groq/sdk`) - optional
- **Development**: Full TypeScript toolchain with Jest, ESLint, and build tools

### Supported Models

- **OpenAI**: `gpt-4`, `gpt-4o`, `gpt-4o-mini`, `gpt-3.5-turbo` and variants
- **Claude**: `claude-3-opus-20240229`, `claude-3-sonnet-20240229`, `claude-3-haiku-20240307`
- **Groq**: `llama-3.1-70b-versatile`, `llama-3.1-8b-instant`, `mixtral-8x7b-32768`, `gemma-7b-it`, `gemma2-9b-it`
- **Grok**: `grok-beta`, `grok-vision-beta`

### Breaking Changes

- This is the initial release, no breaking changes

### Security

- API keys are handled securely and never logged
- All requests use HTTPS with proper authentication
- No sensitive data is stored or cached by default

---

## Release Notes

### 1.0.0 Release Highlights

ðŸŽ‰ **Initial Release** - LLMCore Package is now available!

**Key Benefits:**

- âœ… **No Vendor Lock-in**: Switch between providers with one line of code
- âœ… **Cost Optimization**: Built-in cost tracking across all providers
- âœ… **Type Safety**: Full TypeScript support with comprehensive types
- âœ… **Streaming Support**: Real-time responses from all providers
- âœ… **Production Ready**: Comprehensive error handling and monitoring

**Quick Start:**

```typescript
import { LLMCore } from "llm-core";

const llm = new LLMCore({
  provider: "openai",
  apiKey: process.env.OPENAI_API_KEY,
});

const response = await llm.chat({
  model: "gpt-4o",
  messages: [{ role: "user", content: "Hello, world!" }],
});
```

**Migration Path:**

- Existing OpenAI users: Drop-in replacement with additional features
- Claude users: Seamless migration with consistent API
- Multi-provider users: Significant simplification of codebase

---

## Development

### Adding New Providers

1. Implement `ProviderAdapter` interface
2. Add provider configuration types
3. Create comprehensive tests
4. Update documentation

### Contributing

- Follow conventional commit format
- Ensure 80%+ test coverage
- Update changelog for all changes
- Validate package before PR submission

### Versioning Strategy

- **Major (X.0.0)**: Breaking changes to public API
- **Minor (0.X.0)**: New features, new provider support
- **Patch (0.0.X)**: Bug fixes, optimizations, documentation

For more details, see [CONTRIBUTING.md](CONTRIBUTING.md)
